{
    "personal_details": {
        "job_title": "Sr Data & Cloud Engineer",
        "full_name": "Prakash Pandey",
        "email": "prakashpro86@gmail.com",
        "phone": "7355105172",
        "address": ""
    },
    "professional_summary": "5+ years experience in Data and Cloud Engineering, building data-intensive applications, tackling challenging architectural and scalability problems, designing, testing, and maintenance of software systems in Retails and Sales domain.Experienced with the latest cutting-edge development tools and procedures. Able to effectively self-manage during independent projects, as well as collaborate as part of a productive team.",
    "experience": [
        {
            "job_title": "Senior Software Engineer - Data",
            "employer": "ACL Digital",
            "start": "2023-04-12",
            "end": "",
            "loc": "Bengaluru(Remote)",
            "desc": [
                "Implement Core data processing framework in Javascript for semi-structured data migration and parsing from S3 buckets to Snowflake database supporting 500+ tables",
                "Developed an ETL process to transform data from multiple sources and load it into a data warehouse",
                "Improved and refactored pipeline to dynamically increment path in S3",
                "Developed a data quality framework to standardize and validate data"
                
            ]
        },
        {
            "job_title": "Software Engineer - Frontend & API",
            "employer": "Ugam",
            "start": "2021-12-14",
            "end": "2023-03-21",
            "loc": "Bengaluru",
            "desc": [
                "Worked on Implementing API routes and FrontEnd for dynamic forms"
            ]
        },
        {
            "job_title": "Data Analyst, Engineering",
            "employer": "Denave",
            "start": "2020-02-17",
            "end": "2021-12-12",
            "loc": "Delhi NCR",
            "desc": [
                "Implemented Private API Gateway with Oauth2 authorization using lambda authorizer",
                "Integrated Kafka REST interface on an ECS cluster for producing messages to Kafka topics",
                "Built an ETL framework for batch pipelines. Streamlined usage by introducing a 3 file method (Config, Airflow DAG, and ETL script) thus reducing ETL work",
                "Build a secrets rotation module using AWS Secrets manager and event bridge",
                "Built a data model from scratch sourcing from real-time Kafka streams for retail data in Snowflake DB"
            ]
        },
        {
            "job_title": "Database Analyst",
            "employer": "Denave",
            "start": "2018-11-01",
            "end": "2020-02-14",
            "loc": "Delhi NCR",
            "desc": [
                "Built Data Warehouse with in-depth data validation on data from various sales channels across the world",
                "Prepare and optimized Spark Jobs for batch processes",
                "Developed an automated data cleansing process to reduce manual errors and improve data quality",
                "Developed a data visualization dashboard that enabled users to quickly view and understand complex datasets"
            ]
        }
    ],
    "education": {
        "college": "Lovely Professional University",
        "degree": "Bachelor in Electronics and Communication Engineering",
        "start": "Aug, 2014",
        "end": "June, 2018"
    },
    "course": {
        "type": "Elective Course",
        "college": "IIT, Madras",
        "name": "Data Structures and Algorithms in Python"
    },
    "skills": [
        {
            "name" : "Cloud",
            "level" : "AWS Cloudformation Lambda, ECS, EC2, S3, SNS, ECR"
        },
        {
            "name" : "Big Data",
            "level" : "Kafka, Spark, Hadoop"
        },
        {
            "name" : "Programming",
            "level" : "Python, Javascript, Bash"
        },
        {
            "name" : "Data",
            "level" : "ETL Pipeline, Data Warehousing, Data Modelling, Design"
        },
        {
            "name" : "Database",
            "level" : "Snowflake, PostgresDB, Cassandra"
        },
        {
            "name" : "Platform & Orchestration",
            "level" : "Docker, Airflow"
        },
        {
            "name" : "CI/CD",
            "level" : "Gitlab CI, Jenkins"
        },
        {
            "name" : "Management",
            "level" : "Git, Jira, Confluence, Draw.io"
        }
        
    ],
    "projects": [
        {
            "name": "TechGik",
            "link": "https://techgik.com/",
            "desc": [
                "Built APIs and backend database using Javascript and Postgres based serverless database",
                "Implemented rate-limiting middleware to prevent any DDOS",
                "Integrated backend db in vercel app"
            ],
            "start_date": "2024-04-02",
            "end_date": ""
        },
        {
            "name": "MetaFlakes",
            "link": "https://github.com/prkashp/metaflake",
            "desc": [
                "Frontend was built using the Streamlit library in python",
                "Preprocessing was based on pandas library",
                "Backend was based on snowflake database accounts views to extract table information"
                    ],
            "start_date": "2024-06-22",
            "end_date": ""
        },{
            "name": "Retail Data Model",
            "link": "https://techgik.com/",
            "desc": [
                "Built a retails data model by parsing a complex json payload.",
                "Used snowflake connector to sink events from kafka and parsed them to different tables such as Customers, Transactions,ItemsTransaction, Discounts, ReturnsTransaction. etc. "
            ],
            "start_date": "2023-08-02",
            "end_date": ""
        }
    ],
    "links" : {
        "linkedin": "https://www.linkedin.com/in/prakash-pandey-data-science/",
        "portfolio": "https://prkpro.github.io/",
        "github": "https://github.com/prkashp",
        "medium": "https://medium.com/@prakashpro86"
    }
}